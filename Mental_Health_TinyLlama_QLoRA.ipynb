{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "feabc791"
   },
   "source": [
    "# ðŸš€ Enhance TinyLlama with Advanced Fine-Tuning on Diverse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "066442e8",
    "outputId": "9c7d1e13-21e6-4c8e-c2e8-7c30df8ef613"
   },
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes accelerate datasets loralib peft transformers trl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "d85525b1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "d5a3890b301a433f801f5a8607fd6175",
      "b3048267b1cb4d94b7bbe58b101e0a83",
      "9fbe2f5fc5e742628f1e9f1e2be174d8",
      "8ff87326c0194feaa56a63523cd2901a",
      "740752a4f36b4978b7ddde32bc153f97",
      "2c9f8b374f6e4af5b1b999e3c4c26f41",
      "ca470dbde1e14f709110bac9994411ca",
      "fddc4332fd2e4c35adbe1652a5b39756",
      "d80327294e4f4801aff8e3fa6d42ec72",
      "8e40e259dc78467b933f640cb65ca685",
      "e3b3da27ee2e49e3853b80535ed1de76",
      "1b21a6fc05634198b25849fd898eadb6",
      "28cc1102c31742149164d7588938d4a4",
      "80f6c45bac9f4f8e8c8f79c70ac86e1c",
      "8ae14ff10d7245d1865cb1ccd9023519",
      "a864455278cd40d1b66035f2ff30f4b2",
      "6ffc5faa989644f28ae1fa56455e442a",
      "8d9bed8de50442ea9bcbebcc53447c53",
      "0354008f6c42483fbb8b89de83f27384",
      "de40efb6ced444059b80cd7b5f2e9dcf",
      "56a097f948c14e8199ae24dee22b8049",
      "e4fcfce8b2fb4519adce0cd4b1a61f13",
      "ab23e8ccdbef4edba6edbd9f79a3efda",
      "32d4e3970ab142bc90e139bf7b4c234e",
      "0b78e8a39f494217bc89459ac207f9ba",
      "0d702b19afdd406e86cb906c862dd75a",
      "837730cf45054296acc19ddc35c2c2bd",
      "7b1c98ff7e77494ab24549c8286d434a",
      "82a05f7f2c32493b837a3d7c83ceb728",
      "3abd250ee7fe42ea8a0cd3b231f08356",
      "da6f5816fff74edfb0cc92862f70caa7",
      "16bd9b149ca34f31833bec7a7904c8c1",
      "6a230c0b148d45f1aebba876158fe5ce",
      "db39186f06c94700a012e7863c5add0c",
      "84e46ae2999c4ca4a83cd397eb4b8d2f",
      "79c726c835124f1f8b163f450f848582",
      "5d6b2aa0416c4768813a409220996152",
      "2271ca6364404c66af2b1434bc86d2a7",
      "5d3578b6c18e42beb4a968f9a6043b46",
      "5f982facf6714eec9b728eb8e3bdfb9f",
      "c634c7e26c004cf3a9748da0cee51984",
      "5fc85a80f045400ca47f4bbd1afeea32",
      "4660c12f8e164500807d1bc277661887",
      "92b07840e74047ea8bf7888407729d50",
      "5a66e43990a14e129f7983fb05eb461d",
      "ca3a01ec9fc74b5bbeacb310aea3922e",
      "7dae3b2dc8754b96aca9ddac5b0ccc06",
      "aab49952949848db8dd511d82461502f",
      "63ef2cc7e01148148a2f1adc51a89f12",
      "8cd5b45b3dd34fa5b0e5e52a157c90c7",
      "b9386d42f1e04b0a9f13986d52768de7",
      "e18f8cdd2217461ab7788a76aedce6a4",
      "40315ef21c2b432ca2f19630b7343c02",
      "e7017a214d384bb99fba71a3a5aba760",
      "4a417cb3269b47139bc8fec6609e8807",
      "69fc5229541043db82716084edc0b8f6",
      "406212d618d9476aadcaa5601e45a026",
      "af6a15d4197c4513aae95b6d89b4eb8e",
      "9706a1bcf875410f8cc8daa6e706730e",
      "5ae2687be53242ab8aeedb14656db00f",
      "50b4895544a2489cb5a7f056086f23b2",
      "c665e5ac2629416dacb3c119a8006b84",
      "5a5ff298e2fa4f9b94761a7298a1e537",
      "cb742f1f1b7445969b5ca61cb27e3bbb",
      "9633d64894924cf39e1d38cadc959de3",
      "836899189a3a4bec82e4cf5c36e4a96d",
      "4f47b176352f47fca0790c679ae4b0bd",
      "9a10c116fab04ff9a700cadebf70c7a8",
      "18409f53f9d54c8d844d0078bf84d19a",
      "d640b9af2e7d4779ab59910e73fb513c",
      "b5cd812653de4afdae5a0c2785961a7f",
      "a82da026a8934596a1d1555336c2dbe2",
      "d51b5a485bc24e709f894372fd01d82f",
      "7f16b56e59cb480fa683037bdd79e3c2",
      "c10dc93645ee4825983723c899f58338",
      "cf8b8cb59a254a3484ce1701e67aadf0",
      "0990b7d5b2b7440e9c82dab5985675ba"
     ]
    },
    "id": "4acdc5ae",
    "outputId": "644f87f6-d729-49af-a961-baa568e19b9d"
   },
   "outputs": [],
   "source": [
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.use_cache = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "e50fe3fc"
   },
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "aaa2b3c0a1fc4190bdd63987564ca2ed",
      "9624258ed06445ee8ca79137f64540d2",
      "94715c02398f470e970402d28e7a0616",
      "c40967b4fe3d4f4a8583971642ed0d43",
      "88120cf6f5a943329a3a0441cc61f0fb",
      "6f6fc45d98614ab08fb6c1788750a930",
      "33ec2ba99f534e9eb135cd7ce531620c",
      "a4d303c77c12410f8163ec154c91c7a3",
      "4eb87a0f92664237ab20580a83d2d7b8",
      "8450e8421bac4cdd9b413c4a089b55ad",
      "f8d7815f4e614aa7bc0eff18fc625d55"
     ]
    },
    "id": "xz1Ui3-1dkYu",
    "outputId": "cf14fe85-4784-48f0-c3b1-7a0233f9d2bf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Step 1: Read from output.csv\n",
    "df = pd.read_csv(\"Mental_Health_FAQ.csv\")  # Make sure 'question' and 'answer' columns are present\n",
    "\n",
    "# Step 2: Convert DataFrame to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Step 3: Define formatting function\n",
    "def format_instruction(example):\n",
    "    return f\"### Instruction:\\n{example['Instruction']}\\n\\n### Response:\\n{example['Response']}\"\n",
    "\n",
    "# Step 4: Apply formatting\n",
    "dataset = dataset.map(lambda x: {\"text\": format_instruction(x)})\n",
    "\n",
    "# Optional: Preview\n",
    "print(dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "5caaba73"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c295ae5e8a844de9859e0371fdd9f807",
      "139d96c26ef447f291d64540ff5a27f7",
      "199ae00220fb4f3e9e1344484e88572e",
      "d3a66b1a40134822ac429677a009d898",
      "512370aed1df44b9a60f72398c8dc3bd",
      "9716f5327026429a93cbc9422bee3b4c",
      "6b7ed4fb00cd4a3197d61a4c1e9635ba",
      "214a8fbbe5cc4014b00f678cd74d7ed0",
      "e07b904ad41a43e485e4f2142857741f",
      "1d84ddf8bb1c42208d0cb9e80985dd1b",
      "67f55dfb88d44a2093252a151abfe0f0"
     ]
    },
    "id": "64991825",
    "outputId": "4ed3ae92-fe5a-4ee5-d8cc-55b37cae996f"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    tokenized = tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "74dbc0a4"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./tinyllama-qlora-support-bot\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    logging_dir=\"./logs\",\n",
    "    num_train_epochs=15,\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    bf16=True,\n",
    "    optim=\"paged_adamw_8bit\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ac46d165",
    "outputId": "3fd431b0-23ed-4750-c291-8b284349f40b"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a285233e",
    "outputId": "bfeedac4-b76b-4691-f0f8-38895cae5588"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"tinyllama-qlora-support-bot\")\n",
    "tokenizer.save_pretrained(\"tinyllama-qlora-support-bot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "564eacba",
    "outputId": "e1563d34-c6b8-40fb-9f4e-0f94e038d128"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "instruction = \"What does it mean to have a mental illness?\"\n",
    "prompt = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n\"\n",
    "\n",
    "output = pipe(prompt, max_new_tokens=100)\n",
    "print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "SNWE9TmH4CPl",
    "outputId": "add9244c-714d-4bc7-d71c-586deff61e79"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"tinyllama-qlora-support-bot\", 'zip', \"tinyllama-qlora-support-bot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "1iPAQcWkWRW6",
    "outputId": "f6c5877b-b5a5-4d8f-c681-65bb0c12997b"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download the zipped model to your local system\n",
    "files.download(\"tinyllama-qlora-support-bot.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Vd8SjrCX2tG",
    "outputId": "38f847e7-79b6-43fa-ac71-1e5623b5196c"
   },
   "outputs": [],
   "source": [
    "pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uj0cLzNEYAVh",
    "outputId": "dc863a6c-389b-4bb2-f0c8-000746a27d14"
   },
   "outputs": [],
   "source": [
    "# Mount your Google Drive (optional)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Unzip your fine-tuned model\n",
    "!unzip -o tinyllama-qlora-support-bot.zip -d fine_tuned_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15.5",
   "metadata": {},
   "source": [
    "## ðŸŽ¨ Interactive Web Interface\n",
    "\n",
    "Creating a user-friendly Gradio interface for interacting with our mental health assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "id": "X_q5gnvUwNuS",
    "outputId": "dae98eca-1fef-4064-df4d-37b1e493d0d2"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import gradio as gr\n",
    "\n",
    "# Load your fine-tuned Mental Illness Assistant model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_model\")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def format_prompt(instruction):\n",
    "    return f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n\"\n",
    "\n",
    "def chat_response(message, chat_history):\n",
    "    prompt = format_prompt(message)\n",
    "    output = pipe(prompt, max_new_tokens=300, do_sample=True, temperature=0.7)\n",
    "    generated_text = output[0]['generated_text']\n",
    "    response = generated_text.split(\"### Response:\\n\")[-1].strip()\n",
    "    chat_history.append((message, response))\n",
    "    return \"\", chat_history\n",
    "\n",
    "# Gradio UI for Mental Illness Assistant\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"## ðŸ§  Mental Health Assistant\\nAsk questions about mental illness, symptoms, and care.\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(label=\"Your Question\", placeholder=\"e.g., What does it mean to have anxiety?\", lines=1)\n",
    "    submit = gr.Button(\"Submit\")\n",
    "    clear = gr.Button(\"Clear Chat\")\n",
    "\n",
    "    submit.click(chat_response, [msg, chatbot], [msg, chatbot])\n",
    "    msg.submit(chat_response, [msg, chatbot], [msg, chatbot])  # Also allow Enter key\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "kQdQw7VDb82x",
    "outputId": "cc03efdb-18f8-4162-af40-c4639bd78cf9"
   },
   "outputs": [],
   "source": [
    "# Upload CSV to Google Colab (from local machine)\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "\n",
    "# Method 1: Upload directly from your computer\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the filename (assuming you upload just one file)\n",
    "filename = next(iter(uploaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7fTN5fob9Ro",
    "outputId": "ce58fddc-1c73-4106-9c12-acbb554f0d06"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Mental_Health_FAQ.csv\")\n",
    "print(df.columns)  # Should show: Index(['Questions', 'Answers'], dtype='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "zY7gpBsjfB4s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
